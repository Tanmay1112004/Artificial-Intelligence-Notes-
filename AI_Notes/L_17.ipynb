{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# ⭐ **GAME PLAYING IN ARTIFICIAL INTELLIGENCE (ADVERSARIAL SEARCH) – UNIVERSITY NOTES**\n",
        "\n",
        "---\n",
        "\n",
        "# **1. Introduction to Game Playing in AI**\n",
        "\n",
        "Game Playing is one of the earliest and most important areas of AI.\n",
        "It deals with designing **intelligent agents** that can compete against human or machine opponents using logical decision-making.\n",
        "\n",
        "### **Why important?**\n",
        "\n",
        "* First domain to introduce **multi-agent systems**\n",
        "* Shows how machines make **rational**, strategic decisions\n",
        "* Used in games like Chess, Checkers, Tic-Tac-Toe, Othello, etc.\n",
        "\n",
        "### **AI focuses only on games that are:**\n",
        "\n",
        "1. **Deterministic** (no luck involved)\n",
        "2. **Perfect Information** (all information is visible to both players)\n",
        "3. **Sequential** (players take turns)\n",
        "4. **Zero-Sum** (one player’s gain = other player’s loss)\n",
        "\n",
        "Examples Included:\n",
        "✔ Chess\n",
        "✔ Checkers\n",
        "✔ Tic-Tac-Toe\n",
        "\n",
        "Not Included:\n",
        "❌ Card games\n",
        "❌ Dice-based games\n",
        "(because they involve randomness)\n",
        "\n",
        "---\n",
        "\n",
        "# ⭐ **2. Core Concepts in Adversarial Search**\n",
        "\n",
        "## **(A) What is Adversarial Search?**\n",
        "\n",
        "A search technique where **two agents compete** with opposite goals.\n",
        "\n",
        "* The AI tries to **win or draw**\n",
        "* The opponent tries to **make the AI lose**\n",
        "* Decisions are made by exploring future moves using a **Game Tree**\n",
        "\n",
        "---\n",
        "\n",
        "## **(B) Game Tree**\n",
        "\n",
        "A tree structure showing all possible moves from the current state.\n",
        "\n",
        "* **Nodes** → Game states\n",
        "* **Edges** → Player moves\n",
        "* **Terminal Nodes** → Win, loss, or draw\n",
        "\n",
        "---\n",
        "\n",
        "## **(C) Ply**\n",
        "\n",
        "* A **single move** by one player\n",
        "* Depth of the game tree measured in plies\n",
        "  Example:\n",
        "  MAX moves = 1 ply\n",
        "  MIN moves = next ply\n",
        "\n",
        "---\n",
        "\n",
        "## **(D) Utility Values / Payoff**\n",
        "\n",
        "Assigned at terminal states.\n",
        "\n",
        "Standard Zero-Sum Utility:\n",
        "\n",
        "* **Win** → +1\n",
        "* **Loss** → -1\n",
        "* **Draw** → 0\n",
        "\n",
        "These values help the AI decide which path is best.\n",
        "\n",
        "---\n",
        "\n",
        "# ⭐ **3. Major Algorithms for Game Playing**\n",
        "\n",
        "---\n",
        "\n",
        "# **(A) Minimax Algorithm**\n",
        "\n",
        "A fundamental adversarial search algorithm.\n",
        "\n",
        "### **Idea:**\n",
        "\n",
        "* MAX player → **tries to maximize** the utility\n",
        "* MIN player → **tries to minimize** the utility\n",
        "\n",
        "### **Working:**\n",
        "\n",
        "1. Build the game tree until terminal states\n",
        "2. Assign utility values\n",
        "3. Backpropagate values up the tree\n",
        "4. MAX chooses the **maximum**\n",
        "5. MIN chooses the **minimum**\n",
        "\n",
        "### **Purpose:**\n",
        "\n",
        "To pick the optimal move assuming the opponent also plays optimally.\n",
        "\n",
        "---\n",
        "\n",
        "# **(B) Alpha–Beta Pruning**\n",
        "\n",
        "An enhancement of Minimax.\n",
        "\n",
        "### **Purpose:**\n",
        "\n",
        "To **cut off** branches that cannot affect the final decision.\n",
        "\n",
        "### **Does it change the result?**\n",
        "\n",
        "❌ No\n",
        "✔ It only removes useless branches\n",
        "✔ Same decision as Minimax\n",
        "✔ But **much faster**\n",
        "\n",
        "### **Benefits:**\n",
        "\n",
        "* Searches deeper levels within same time\n",
        "* Reduces number of nodes evaluated\n",
        "\n",
        "---\n",
        "\n",
        "# ⭐ **4. University-Type Long Answers**\n",
        "\n",
        "---\n",
        "\n",
        "## **Q1. Define Adversarial Search and explain the roles of MAX and MIN in Minimax.**\n",
        "\n",
        "### **Answer:**\n",
        "\n",
        "Adversarial Search is a search technique used in environments where multiple agents operate with **opposing goals**, such as in competitive games.\n",
        "Each agent must consider not only its own moves but also the best possible responses from the opponent.\n",
        "\n",
        "In the **Minimax algorithm:**\n",
        "\n",
        "### ✔ **MAX Player (the AI Agent):**\n",
        "\n",
        "* Goal: **Maximize** the utility value\n",
        "* Chooses the move that leads to the **highest** payoff\n",
        "\n",
        "### ✔ **MIN Player (the Opponent):**\n",
        "\n",
        "* Goal: **Minimize** MAX’s utility value\n",
        "* Chooses the move that gives MAX the **lowest** payoff\n",
        "\n",
        "The algorithm alternates between MAX and MIN layers, eventually selecting the best possible move assuming optimal play from both sides.\n",
        "\n",
        "---\n",
        "\n",
        "## **Q2. Explain the limitation of BFS/DFS in Game Trees and how Alpha-Beta Pruning solves it.**\n",
        "\n",
        "### **Answer:**\n",
        "\n",
        "Basic search strategies like BFS and DFS fail in game playing because:\n",
        "\n",
        "### **Limitations:**\n",
        "\n",
        "* Game trees have a **very high branching factor (b)**\n",
        "* Game depth is large (d) — e.g., chess = 40+ plies\n",
        "* Total nodes ≈ **O(bᵈ)** → exponential growth\n",
        "* Impossible to search the full tree due to computational limits\n",
        "\n",
        "### **Alpha-Beta Pruning Solution:**\n",
        "\n",
        "* It eliminates branches that cannot influence the final Minimax decision\n",
        "* Checks if a node is worse than a previously explored option\n",
        "* If yes → **prune it** (stop exploring further)\n",
        "\n",
        "### **Result:**\n",
        "\n",
        "* Same optimal move as Minimax\n",
        "* Far fewer nodes evaluated\n",
        "* Can explore deeper levels within limited time\n",
        "\n",
        "---\n",
        "\n",
        "# ⭐ **5. MCQs (with Answers)**\n",
        "\n",
        "### **1. Game Playing in AI is categorized under:**\n",
        "\n",
        "✔ **C. Adversarial Search**\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Ply refers to:**\n",
        "\n",
        "✔ **C. The depth representing one move by a player**\n",
        "\n",
        "---\n",
        "\n",
        "### **3. A utility value of +1 means:**\n",
        "\n",
        "✔ **C. A Win for the MAX player**\n",
        "\n",
        "---\n",
        "\n",
        "### **4. The MIN player’s goal is to:**\n",
        "\n",
        "✔ **C. Minimize the maximum utility value of MAX**\n",
        "\n",
        "---\n",
        "\n",
        "# ⭐ Final Revision Tip\n",
        "\n",
        "If the question mentions:\n",
        "\n",
        "* Two players\n",
        "* Opposite goals\n",
        "* Game tree\n",
        "* Utility values\n",
        "* Win/Loss evaluation\n",
        "\n",
        "→ The answer is ALWAYS from **Adversarial Search (Minimax + Alpha-Beta)**.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "AtSTq0Y_qJTP"
      }
    }
  ]
}